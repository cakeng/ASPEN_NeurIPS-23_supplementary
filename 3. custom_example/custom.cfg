# [net] defines the first layer, i.e. input of the network.
# As we are using Cifar-10 dataset, the input size is 32x32x3 (height x width x channels).
[net] 

height=32
width=32
channels=3

# Layer 1: A convolution layer with 6 filters of size 5x5, stride 1 and pad 0, and a ReLU activation.
[convolutional]
filters=32
size=5
stride=1
pad=2
activation=relu

# Layer 2: A maxpool layer with size 2x2 and stride 2.
[maxpool]
size=2
stride=2

# Layer 3: A convolution layer with 16 filters of size 5x5, stride 1 and pad 0, and a ReLU activation.
[convolutional]
filters=64
size=3
stride=1
pad=1
activation=relu

# Layer 4: A maxpool layer with size 2x2 and stride 2.
[maxpool]
size=2
stride=2

# Layer 5: A fully connected (linear) layer with 120 filters and a ReLU activation.
[connected]
output=256
# activation=relu

# Layer 6: A fully connected (linear) layer with 84 filters and a ReLU activation.
[connected]
output=128
activation=relu

# Layer 7: A fully connected (linear) layer with 10 filters and a linear (no) activation.
[connected]
output=10
activation=linear



